{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "url= 'https://scholar.google.com/scholar'\n",
    "\n",
    "#set headers\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) \\\n",
    "    AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36' \n",
    "    #english\n",
    "}\n",
    "\n",
    "params = {\n",
    "    #english\n",
    "    'hl': 'en',\n",
    "\n",
    "    'start': 0,\n",
    "    'q': 'heat stress guidlines interventions mitigation strategies' \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa9595e99dc40398d86595624ee1448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##GET TITLE/LINK/AUTHORS OF N*10 ARTICLES\n",
    "\n",
    "#loop through pages for n pages\n",
    "n = 5\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "#store results\n",
    "results = pd.DataFrame(columns=['title', 'link', 'author'])\n",
    "\n",
    "for i in tqdm(range(n)):\n",
    "    params['start'] = i*10\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    articles = soup.find_all('div', class_='gs_ri')\n",
    "\n",
    "    #get titles\n",
    "    titles = [article.find('h3', class_='gs_rt').text for article in articles]\n",
    "    #get links\n",
    "    links = [article.find('h3', class_='gs_rt').find('a')['href'] for article in articles]\n",
    "    #get authors\n",
    "    authors = [article.find('div', class_='gs_a').text for article in articles]\n",
    "    \n",
    "    #add to results\n",
    "    results = results._append(pd.DataFrame({'title': titles, 'link': links, 'author': authors}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('article_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BASIC CODE TO SCRAPE ABSTRACT \n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_abstract(url):\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        abstract = soup.find('blockquote', class_='abstract').text.strip()\n",
    "    \n",
    "    return abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [400]>\n"
     ]
    }
   ],
   "source": [
    "link = 'https://www.sciencedirect.com/science/article/pii/S0921800919302976'\n",
    "\n",
    "response = requests.get(link, headers=headers)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CODE TO DOWNLOAD 1 LINK\n",
    "\n",
    "from selenium import webdriver\n",
    "\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import time\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "main_page_url = 'https://sci-hub.ru/'\n",
    "url_to_search = 'https://www.sciencedirect.com/science/article/pii/S0921800919302976'\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "try:\n",
    "    # Open page\n",
    "    driver.get(main_page_url)\n",
    "    time.sleep(2)  # Wait for the page to load (you can decrease this time if need be)\n",
    "\n",
    "    #doi_input = driver.find_element()\n",
    "    # Find search bar -> input URL\n",
    "    search_bar = driver.find_element(by=By.ID, value='request')\n",
    "    search_bar.send_keys(url_to_search)\n",
    "    search_bar.send_keys(Keys.RETURN)  # To submit the search query\n",
    "    time.sleep(1)  # Wait for a bit again\n",
    "\n",
    "    # Find download link\n",
    "    download_button = driver.find_element(by=By.XPATH, value=\"//button[@onclick]\")\n",
    "    onclick_attribute = download_button.get_attribute('onclick')\n",
    "\n",
    "    # Extract URL from the onclick attribute\n",
    "    # Assuming the format is location.href='URL'\n",
    "    pdf_url = onclick_attribute.split(\"'\")[1]\n",
    "    \n",
    "    download_link = 'https://' + urlparse(main_page_url).hostname + pdf_url\n",
    "  \n",
    "    # Download the PDF using requests\n",
    "    response = requests.get(download_link)\n",
    "\n",
    "    with open('pdf.pdf', 'wb') as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "except Exception as e:\n",
    "    # Handle the exception, print an error message, etc.\n",
    "    print(f\"An error occurred: {str(e)}\")\n",
    "finally:\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping function\n",
    "\n",
    "from selenium import webdriver\n",
    "\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import time\n",
    "import requests\n",
    "\n",
    "def pdf_download(url_to_search, file_name):\n",
    "    driver = webdriver.Chrome() #initialize web-finder\n",
    "    main_page_url = 'https://sci-hub.ru/' #open sci-hub\n",
    "    driver.get(main_page_url)\n",
    "    time.sleep(1)\n",
    "    # Find search bar -> input URL\n",
    "    search_bar = driver.find_element(by=By.ID, value='request')\n",
    "    search_bar.send_keys(url_to_search)\n",
    "    search_bar.send_keys(Keys.RETURN)  # To submit the search query\n",
    "    time.sleep(1)\n",
    "    \n",
    "    try:\n",
    "        # Find download link\n",
    "        download_button = driver.find_element(by=By.XPATH, value=\"//button[@onclick]\")\n",
    "        onclick_attribute = download_button.get_attribute('onclick')\n",
    "    except:\n",
    "        driver.quit()\n",
    "        return url_to_search\n",
    "\n",
    "    \n",
    "    # Extract URL from the onclick attribute\n",
    "    # Assuming the format is location.href='URL'\n",
    "    pdf_url = onclick_attribute.split(\"'\")[1]\n",
    "    download_link = 'https://sci-hub.ru' + pdf_url\n",
    "    # Download the PDF using requests\n",
    "    response = requests.get(download_link)\n",
    "    with open(f'pdfs/{file_name}.pdf', 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    \n",
    "    driver.quit()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "##to call on all links !!! DO NOT RERUN, IT WILL SET LIST BACK TO NONE\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data = pd.read_csv('article_info.csv')\n",
    "title = data['title']\n",
    "links = data['link']\n",
    "author = ['author'] \n",
    "\n",
    "\n",
    "def file_exists(file_path):\n",
    "    return os.path.exists(file_path)\n",
    "\n",
    "list_error_links = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR FOR https://www.jstage.jst.go.jp/article/indhealth/51/1/51_2012-0089/_article/-char/ja/\n",
      "ERROR FOR https://journals.lww.com/joem/fulltext/2019/09000/Effect_of_Multivitamin_and_Multimineral.4.aspx\n",
      "ERROR FOR https://www.aivc.org/resource/heat-waves-risks-and-responses\n",
      "ERROR FOR https://www.researchgate.net/profile/Veerasamy-Sejian/publication/313548685_Behavioral_Responses_to_Livestock_Adaptation_to_Heat_Stress_Challenges/links/58c3d52fa6fdcce648e0a02d/Behavioral-Responses-to-Livestock-Adaptation-to-Heat-Stress-Challenges.pdf\n",
      "ERROR FOR https://journals.uni-lj.si/aas/article/view/12783\n",
      "ERROR FOR https://meridian.allenpress.com/jat/article-abstract/50/9/986/112280\n",
      "ERROR FOR https://www.mdpi.com/1422-0067/18/9/1978\n",
      "ERROR FOR https://journals.lww.com/co-clinicalnutrition/fulltext/2015/07000/Heat_shock_proteins_and_heat_therapy_for_type_2.10.aspx\n",
      "ERROR FOR https://www.mdpi.com/1660-4601/18/9/4486\n",
      "ERROR FOR https://jamanetwork.com/journals/jamainternalmedicine/article-abstract/413470\n",
      "ERROR FOR https://jamanetwork.com/journals/jama/article-abstract/1909928\n",
      "ERROR FOR https://researchportal.port.ac.uk/files/3398222/Heat_acclimation.pdf\n",
      "ERROR FOR https://books.google.com/books?hl=en&lr=&id=D9pNrH6U0oYC&oi=fnd&pg=PR7&dq=heat+stress+guidlines+interventions+mitigation+strategies&ots=Uwmb9KlRII&sig=rkgjXCbcnpyjnEQlxGpkFQHLBhQ\n",
      "ERROR FOR https://academic.oup.com/eurheartj/article-abstract/38/8/550/3056923\n"
     ]
    },
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"[id=\"request\"]\"}\n  (Session info: chrome=134.0.6998.118); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF749554C25+3179557]\n\t(No symbol) [0x00007FF7491B88A0]\n\t(No symbol) [0x00007FF7490491CA]\n\t(No symbol) [0x00007FF74909FA67]\n\t(No symbol) [0x00007FF74909FC9C]\n\t(No symbol) [0x00007FF7490F3627]\n\t(No symbol) [0x00007FF7490C7C6F]\n\t(No symbol) [0x00007FF7490F02F3]\n\t(No symbol) [0x00007FF7490C7A03]\n\t(No symbol) [0x00007FF7490906D0]\n\t(No symbol) [0x00007FF749091983]\n\tGetHandleVerifier [0x00007FF7495B67CD+3579853]\n\tGetHandleVerifier [0x00007FF7495CD1D2+3672530]\n\tGetHandleVerifier [0x00007FF7495C2153+3627347]\n\tGetHandleVerifier [0x00007FF74932092A+868650]\n\t(No symbol) [0x00007FF7491C2FFF]\n\t(No symbol) [0x00007FF7491BF4A4]\n\t(No symbol) [0x00007FF7491BF646]\n\t(No symbol) [0x00007FF7491AEAA9]\n\tBaseThreadInitThunk [0x00007FFD3EE2259D+29]\n\tRtlUserThreadStart [0x00007FFD3F9AAF38+40]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror already encountered\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 11\u001b[0m     url_returned \u001b[38;5;241m=\u001b[39m \u001b[43mpdf_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlink\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m#(links[index], index)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m url_returned \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     13\u001b[0m         list_error_links\u001b[38;5;241m.\u001b[39mappend(url_returned)\n",
      "Cell \u001b[1;32mIn[31], line 17\u001b[0m, in \u001b[0;36mpdf_download\u001b[1;34m(url_to_search, file_name)\u001b[0m\n\u001b[0;32m     15\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Find search bar -> input URL\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m search_bar \u001b[38;5;241m=\u001b[39m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mby\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mID\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrequest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m search_bar\u001b[38;5;241m.\u001b[39msend_keys(url_to_search)\n\u001b[0;32m     19\u001b[0m search_bar\u001b[38;5;241m.\u001b[39msend_keys(Keys\u001b[38;5;241m.\u001b[39mRETURN)  \u001b[38;5;66;03m# To submit the search query\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:738\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    735\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    736\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 738\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:344\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    342\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 344\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    345\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"[id=\"request\"]\"}\n  (Session info: chrome=134.0.6998.118); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF749554C25+3179557]\n\t(No symbol) [0x00007FF7491B88A0]\n\t(No symbol) [0x00007FF7490491CA]\n\t(No symbol) [0x00007FF74909FA67]\n\t(No symbol) [0x00007FF74909FC9C]\n\t(No symbol) [0x00007FF7490F3627]\n\t(No symbol) [0x00007FF7490C7C6F]\n\t(No symbol) [0x00007FF7490F02F3]\n\t(No symbol) [0x00007FF7490C7A03]\n\t(No symbol) [0x00007FF7490906D0]\n\t(No symbol) [0x00007FF749091983]\n\tGetHandleVerifier [0x00007FF7495B67CD+3579853]\n\tGetHandleVerifier [0x00007FF7495CD1D2+3672530]\n\tGetHandleVerifier [0x00007FF7495C2153+3627347]\n\tGetHandleVerifier [0x00007FF74932092A+868650]\n\t(No symbol) [0x00007FF7491C2FFF]\n\t(No symbol) [0x00007FF7491BF4A4]\n\t(No symbol) [0x00007FF7491BF646]\n\t(No symbol) [0x00007FF7491AEAA9]\n\tBaseThreadInitThunk [0x00007FFD3EE2259D+29]\n\tRtlUserThreadStart [0x00007FFD3F9AAF38+40]\n"
     ]
    }
   ],
   "source": [
    "#function to call on all links\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    pdf_file_path = f'pdfs/{index}.pdf'\n",
    "    if file_exists(pdf_file_path) is True:\n",
    "        print(\"PDF already downloaded\")\n",
    "    else:\n",
    "        if row['link'] in list_error_links:\n",
    "            print('error already encountered')\n",
    "        else:\n",
    "            url_returned = pdf_download(row['link'], index)  #(links[index], index)\n",
    "            if url_returned is not None:\n",
    "                list_error_links.append(url_returned)\n",
    "                print(f'ERROR FOR {url_returned}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in c:\\users\\gur levy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (3.17.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\Gur Levy\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 0.pdf...\n",
      "0.pdf has 16 pages!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 10.pdf...\n"
     ]
    },
    {
     "ename": "PdfStreamError",
     "evalue": "Stream has ended unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPdfStreamError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pdf \u001b[38;5;129;01min\u001b[39;00m pdf_folder_content:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnalyzing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpdf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m     reader \u001b[38;5;241m=\u001b[39m \u001b[43mPdfReader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmypath\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpdf\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     n_pages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(reader\u001b[38;5;241m.\u001b[39mpages)\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpdf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_pages\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m pages!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pypdf\\_reader.py:332\u001b[0m, in \u001b[0;36mPdfReader.__init__\u001b[1;34m(self, stream, strict, password)\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(stream, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[0;32m    331\u001b[0m         stream \u001b[38;5;241m=\u001b[39m BytesIO(fh\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m--> 332\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;241m=\u001b[39m stream\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_override_encryption \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pypdf\\_reader.py:1555\u001b[0m, in \u001b[0;36mPdfReader.read\u001b[1;34m(self, stream)\u001b[0m\n\u001b[0;32m   1553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, stream: StreamType) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1554\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_basic_validation(stream)\n\u001b[1;32m-> 1555\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_find_eof_marker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1556\u001b[0m     startxref \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_startxref_pos(stream)\n\u001b[0;32m   1558\u001b[0m     \u001b[38;5;66;03m# check and eventually correct the startxref only in not strict\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pypdf\\_reader.py:1626\u001b[0m, in \u001b[0;36mPdfReader._find_eof_marker\u001b[1;34m(self, stream)\u001b[0m\n\u001b[0;32m   1624\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1625\u001b[0m         logger_warning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEOF marker not found\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m-> 1626\u001b[0m line \u001b[38;5;241m=\u001b[39m \u001b[43mread_previous_line\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pypdf\\_utils.py:269\u001b[0m, in \u001b[0;36mread_previous_line\u001b[1;34m(stream)\u001b[0m\n\u001b[0;32m    267\u001b[0m found_crlf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream\u001b[38;5;241m.\u001b[39mtell() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 269\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PdfStreamError(STREAM_TRUNCATED_PREMATURELY)\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    271\u001b[0m     to_read \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(DEFAULT_BUFFER_SIZE, stream\u001b[38;5;241m.\u001b[39mtell())\n",
      "\u001b[1;31mPdfStreamError\u001b[0m: Stream has ended unexpectedly"
     ]
    }
   ],
   "source": [
    "from pypdf import PdfReader\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "mypath = 'C:\\\\CAPSTONE\\\\scholar scraper\\\\pdfs'\n",
    "\n",
    "pdf_folder_content = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "\n",
    "all_pdf_texts = []\n",
    "\n",
    "for pdf in pdf_folder_content:\n",
    "    print(f'Analyzing {pdf}...')\n",
    "\t\n",
    "    reader = PdfReader(f'{mypath}/{pdf}')\n",
    "\n",
    "    n_pages = len(reader.pages)\n",
    "\t\n",
    "    print(f'{pdf} has {n_pages} pages!')\n",
    "\n",
    "    all_text = []\n",
    "\n",
    "    for i in range(0,n_pages):  \n",
    "      page_text = reader.pages[i].extract_text()\n",
    "      all_text.append(page_text)\n",
    "\n",
    "    result_string = ' '.join(all_text)\n",
    "    all_pdf_texts.append(result_string)\n",
    "\n",
    "##SWITCH TO A DICTIONARY INSTEAD OF A LIST\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
