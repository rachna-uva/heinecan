{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Gur Levy\\\\heinecan-2\\\\scholar scraper'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: natsort in c:\\users\\gur levy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (8.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\Gur Levy\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install natsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 66 PDFs in folder!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b06e758745d34481a7e794643f10c4d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing PDFs:   0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 0.pdf...\n",
      "0.pdf has 16 pages!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 2.pdf...\n",
      "Error reading 2.pdf: Stream has ended unexpectedly\n",
      "Analyzing 3.pdf...\n",
      "Error reading 3.pdf: Stream has ended unexpectedly\n",
      "Analyzing 4.pdf...\n",
      "Error reading 4.pdf: Stream has ended unexpectedly\n",
      "Analyzing 5.pdf...\n",
      "Error reading 5.pdf: Stream has ended unexpectedly\n",
      "Analyzing 6.pdf...\n",
      "6.pdf has 23 pages!\n",
      "Analyzing 7.pdf...\n",
      "7.pdf has 11 pages!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 8.pdf...\n",
      "Error reading 8.pdf: Stream has ended unexpectedly\n",
      "Analyzing 9.pdf...\n",
      "Error reading 9.pdf: Stream has ended unexpectedly\n",
      "Analyzing 10.pdf...\n",
      "Error reading 10.pdf: Stream has ended unexpectedly\n",
      "Analyzing 11.pdf...\n",
      "Error reading 11.pdf: Stream has ended unexpectedly\n",
      "Analyzing 14.pdf...\n",
      "Error reading 14.pdf: Stream has ended unexpectedly\n",
      "Analyzing 15.pdf...\n",
      "Error reading 15.pdf: Stream has ended unexpectedly\n",
      "Analyzing 16.pdf...\n",
      "Error reading 16.pdf: Stream has ended unexpectedly\n",
      "Analyzing 17.pdf...\n",
      "Error reading 17.pdf: Stream has ended unexpectedly\n",
      "Analyzing 18.pdf...\n",
      "18.pdf has 16 pages!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 20.pdf...\n",
      "Error reading 20.pdf: Stream has ended unexpectedly\n",
      "Analyzing 22.pdf...\n",
      "Error reading 22.pdf: Stream has ended unexpectedly\n",
      "Analyzing 23.pdf...\n",
      "Error reading 23.pdf: Stream has ended unexpectedly\n",
      "Analyzing 25.pdf...\n",
      "Error reading 25.pdf: Stream has ended unexpectedly\n",
      "Analyzing 28.pdf...\n",
      "Error reading 28.pdf: Stream has ended unexpectedly\n",
      "Analyzing 31.pdf...\n",
      "Error reading 31.pdf: Stream has ended unexpectedly\n",
      "Analyzing 32.pdf...\n",
      "Error reading 32.pdf: Stream has ended unexpectedly\n",
      "Analyzing 34.pdf...\n",
      "Error reading 34.pdf: Stream has ended unexpectedly\n",
      "Analyzing 35.pdf...\n",
      "Error reading 35.pdf: Stream has ended unexpectedly\n",
      "Analyzing 36.pdf...\n",
      "Error reading 36.pdf: Stream has ended unexpectedly\n",
      "Analyzing 37.pdf...\n",
      "Error reading 37.pdf: Stream has ended unexpectedly\n",
      "Analyzing 38.pdf...\n",
      "Error reading 38.pdf: Stream has ended unexpectedly\n",
      "Analyzing 39.pdf...\n",
      "Error reading 39.pdf: Stream has ended unexpectedly\n",
      "Analyzing 41.pdf...\n",
      "Error reading 41.pdf: Stream has ended unexpectedly\n",
      "Analyzing 43.pdf...\n",
      "Error reading 43.pdf: Stream has ended unexpectedly\n",
      "Analyzing 46.pdf...\n",
      "Error reading 46.pdf: Stream has ended unexpectedly\n",
      "Analyzing 47.pdf...\n",
      "Error reading 47.pdf: Stream has ended unexpectedly\n",
      "Analyzing 50.pdf...\n",
      "Error reading 50.pdf: Stream has ended unexpectedly\n",
      "Analyzing 51.pdf...\n",
      "Error reading 51.pdf: Stream has ended unexpectedly\n",
      "Analyzing 52.pdf...\n",
      "Error reading 52.pdf: Stream has ended unexpectedly\n",
      "Analyzing 53.pdf...\n",
      "Error reading 53.pdf: Stream has ended unexpectedly\n",
      "Analyzing 56.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading 56.pdf: Stream has ended unexpectedly\n",
      "Analyzing 60.pdf...\n",
      "Error reading 60.pdf: Stream has ended unexpectedly\n",
      "Analyzing 61.pdf...\n",
      "Error reading 61.pdf: Stream has ended unexpectedly\n",
      "Analyzing 62.pdf...\n",
      "Error reading 62.pdf: Stream has ended unexpectedly\n",
      "Analyzing 63.pdf...\n",
      "Error reading 63.pdf: Stream has ended unexpectedly\n",
      "Analyzing 64.pdf...\n",
      "64.pdf has 14 pages!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 66.pdf...\n",
      "Error reading 66.pdf: Stream has ended unexpectedly\n",
      "Analyzing 67.pdf...\n",
      "67.pdf has 192 pages!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'62.45'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 69.pdf...\n",
      "Error reading 69.pdf: Stream has ended unexpectedly\n",
      "Analyzing 72.pdf...\n",
      "Error reading 72.pdf: Stream has ended unexpectedly\n",
      "Analyzing 73.pdf...\n",
      "Error reading 73.pdf: Stream has ended unexpectedly\n",
      "Analyzing 78.pdf...\n",
      "Error reading 78.pdf: Stream has ended unexpectedly\n",
      "Analyzing 79.pdf...\n",
      "Error reading 79.pdf: Stream has ended unexpectedly\n",
      "Analyzing 82.pdf...\n",
      "Error reading 82.pdf: Stream has ended unexpectedly\n",
      "Analyzing 83.pdf...\n",
      "83.pdf has 17 pages!\n",
      "Analyzing 84.pdf...\n",
      "84.pdf has 13 pages!\n",
      "Analyzing 85.pdf...\n",
      "85.pdf has 11 pages!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 86.pdf...\n",
      "Error reading 86.pdf: Stream has ended unexpectedly\n",
      "Analyzing 87.pdf...\n",
      "Error reading 87.pdf: Stream has ended unexpectedly\n",
      "Analyzing 88.pdf...\n",
      "Error reading 88.pdf: Stream has ended unexpectedly\n",
      "Analyzing 90.pdf...\n",
      "Error reading 90.pdf: Stream has ended unexpectedly\n",
      "Analyzing 91.pdf...\n",
      "Error reading 91.pdf: Stream has ended unexpectedly\n",
      "Analyzing 92.pdf...\n",
      "Error reading 92.pdf: Stream has ended unexpectedly\n",
      "Analyzing 93.pdf...\n",
      "93.pdf has 17 pages!\n",
      "Analyzing 94.pdf...\n",
      "94.pdf has 14 pages!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 96.pdf...\n",
      "Error reading 96.pdf: Stream has ended unexpectedly\n",
      "Analyzing 97.pdf...\n",
      "97.pdf has 68 pages!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 98.pdf...\n",
      "Error reading 98.pdf: Stream has ended unexpectedly\n",
      "Analyzing 99.pdf...\n",
      "Error reading 99.pdf: Stream has ended unexpectedly\n"
     ]
    }
   ],
   "source": [
    "from natsort import natsorted\n",
    "from pypdf import PdfReader\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "mypath = 'pdfs'\n",
    "\n",
    "# Use natsorted to sort files in a natural order\n",
    "pdf_folder_content = natsorted([f for f in listdir(mypath) if isfile(join(mypath, f)) and f.lower().endswith('.pdf')])\n",
    "\n",
    "print(f'Found {len(pdf_folder_content)} PDFs in folder!')\n",
    "\n",
    "all_pdf_texts = []\n",
    "\n",
    "for pdf in tqdm(pdf_folder_content, desc=\"Processing PDFs\"):\n",
    "\n",
    "    print(f'Analyzing {pdf}...')\n",
    "\n",
    "    try:\n",
    "        reader = PdfReader(join(mypath, pdf))\n",
    "    except Exception as e:\n",
    "        print(f'Error reading {pdf}: {e}')\n",
    "        continue\n",
    "\n",
    "    n_pages = len(reader.pages)\n",
    "\n",
    "    print(f'{pdf} has {n_pages} pages!')\n",
    "\n",
    "    all_text = []\n",
    "\n",
    "    for i in range(0, n_pages):\n",
    "        page_text = reader.pages[i].extract_text()\n",
    "        # print(page_text)\n",
    "        all_text.append(page_text)\n",
    "\n",
    "    result_string = ' '.join(all_text)\n",
    "    all_pdf_texts.append(result_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['main', 'heat_stress', 'mitigation', 'practice']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import string\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "additional_stopwords = ['et', 'al','b', 'fw', 'e', 'j', 'ce']\n",
    "\n",
    "# Define specific multi-word phrases to be combined\n",
    "phrase_mapping = {'heat stress': 'heat_stress'}\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # removes special characters and punctuation (STEP 1: Text cleaning)\n",
    "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
    "    # remove additional white spaces (STEP 1: Text cleaning)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    # put text in lowercases (STEP 2: Case normalization)\n",
    "    text = text.lower()\n",
    "\n",
    "    # Replace specific multi-word phrases with combined tokens\n",
    "    for phrase, replacement in phrase_mapping.items():\n",
    "        text = text.replace(phrase, replacement)\n",
    "\n",
    "    # STEP 3: Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # STEP 4: Removing stopwords\n",
    "    stopwords_list = set(stopwords.words('english')).union(additional_stopwords)\n",
    "    tokens = [token for token in tokens if token not in stopwords_list]\n",
    "\n",
    "    # STEP 5: Lemmatization\n",
    "    lemmatized_words = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    return lemmatized_words\n",
    "\n",
    "# Example\n",
    "text = \"There are 5 main heat stress mitigation practices\"\n",
    "processed_text = preprocess_text(text)\n",
    "print(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 66 PDFs in folder!\n",
      "Analyzing 0.pdf...\n",
      "0.pdf has 16 pages!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 10.pdf...\n",
      "Error reading 10.pdf!\n",
      "Analyzing 11.pdf...\n",
      "Error reading 11.pdf!\n",
      "Analyzing 14.pdf...\n",
      "Error reading 14.pdf!\n",
      "Analyzing 15.pdf...\n",
      "Error reading 15.pdf!\n",
      "Analyzing 16.pdf...\n",
      "Error reading 16.pdf!\n",
      "Analyzing 17.pdf...\n",
      "Error reading 17.pdf!\n",
      "Analyzing 18.pdf...\n",
      "18.pdf has 16 pages!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 2.pdf...\n",
      "Error reading 2.pdf!\n",
      "Analyzing 20.pdf...\n",
      "Error reading 20.pdf!\n",
      "Analyzing 22.pdf...\n",
      "Error reading 22.pdf!\n",
      "Analyzing 23.pdf...\n",
      "Error reading 23.pdf!\n",
      "Analyzing 25.pdf...\n",
      "Error reading 25.pdf!\n",
      "Analyzing 28.pdf...\n",
      "Error reading 28.pdf!\n",
      "Analyzing 3.pdf...\n",
      "Error reading 3.pdf!\n",
      "Analyzing 31.pdf...\n",
      "Error reading 31.pdf!\n",
      "Analyzing 32.pdf...\n",
      "Error reading 32.pdf!\n",
      "Analyzing 34.pdf...\n",
      "Error reading 34.pdf!\n",
      "Analyzing 35.pdf...\n",
      "Error reading 35.pdf!\n",
      "Analyzing 36.pdf...\n",
      "Error reading 36.pdf!\n",
      "Analyzing 37.pdf...\n",
      "Error reading 37.pdf!\n",
      "Analyzing 38.pdf...\n",
      "Error reading 38.pdf!\n",
      "Analyzing 39.pdf...\n",
      "Error reading 39.pdf!\n",
      "Analyzing 4.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading 4.pdf!\n",
      "Analyzing 41.pdf...\n",
      "Error reading 41.pdf!\n",
      "Analyzing 43.pdf...\n",
      "Error reading 43.pdf!\n",
      "Analyzing 46.pdf...\n",
      "Error reading 46.pdf!\n",
      "Analyzing 47.pdf...\n",
      "Error reading 47.pdf!\n",
      "Analyzing 5.pdf...\n",
      "Error reading 5.pdf!\n",
      "Analyzing 50.pdf...\n",
      "Error reading 50.pdf!\n",
      "Analyzing 51.pdf...\n",
      "Error reading 51.pdf!\n",
      "Analyzing 52.pdf...\n",
      "Error reading 52.pdf!\n",
      "Analyzing 53.pdf...\n",
      "Error reading 53.pdf!\n",
      "Analyzing 56.pdf...\n",
      "Error reading 56.pdf!\n",
      "Analyzing 6.pdf...\n",
      "6.pdf has 23 pages!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 60.pdf...\n",
      "Error reading 60.pdf!\n",
      "Analyzing 61.pdf...\n",
      "Error reading 61.pdf!\n",
      "Analyzing 62.pdf...\n",
      "Error reading 62.pdf!\n",
      "Analyzing 63.pdf...\n",
      "Error reading 63.pdf!\n",
      "Analyzing 64.pdf...\n",
      "64.pdf has 14 pages!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 66.pdf...\n",
      "Error reading 66.pdf!\n",
      "Analyzing 67.pdf...\n",
      "67.pdf has 192 pages!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 69.pdf...\n",
      "Error reading 69.pdf!\n",
      "Analyzing 7.pdf...\n",
      "7.pdf has 11 pages!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'62.45'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 72.pdf...\n",
      "Error reading 72.pdf!\n",
      "Analyzing 73.pdf...\n",
      "Error reading 73.pdf!\n",
      "Analyzing 78.pdf...\n",
      "Error reading 78.pdf!\n",
      "Analyzing 79.pdf...\n",
      "Error reading 79.pdf!\n",
      "Analyzing 8.pdf...\n",
      "Error reading 8.pdf!\n",
      "Analyzing 82.pdf...\n",
      "Error reading 82.pdf!\n",
      "Analyzing 83.pdf...\n",
      "83.pdf has 17 pages!\n",
      "Analyzing 84.pdf...\n",
      "84.pdf has 13 pages!\n",
      "Analyzing 85.pdf...\n",
      "85.pdf has 11 pages!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 86.pdf...\n",
      "Error reading 86.pdf!\n",
      "Analyzing 87.pdf...\n",
      "Error reading 87.pdf!\n",
      "Analyzing 88.pdf...\n",
      "Error reading 88.pdf!\n",
      "Analyzing 9.pdf...\n",
      "Error reading 9.pdf!\n",
      "Analyzing 90.pdf...\n",
      "Error reading 90.pdf!\n",
      "Analyzing 91.pdf...\n",
      "Error reading 91.pdf!\n",
      "Analyzing 92.pdf...\n",
      "Error reading 92.pdf!\n",
      "Analyzing 93.pdf...\n",
      "93.pdf has 17 pages!\n",
      "Analyzing 94.pdf...\n",
      "94.pdf has 14 pages!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 96.pdf...\n",
      "Error reading 96.pdf!\n",
      "Analyzing 97.pdf...\n",
      "97.pdf has 68 pages!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 98.pdf...\n",
      "Error reading 98.pdf!\n",
      "Analyzing 99.pdf...\n",
      "Error reading 99.pdf!\n"
     ]
    }
   ],
   "source": [
    "from pypdf import PdfReader\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "mypath = 'pdfs'\n",
    "\n",
    "pdf_folder_content = [f for f in listdir(mypath) if isfile(join(mypath, f)) and f.lower().endswith('.pdf')]\n",
    "\n",
    "print(f'Found {len(pdf_folder_content)} PDFs in folder!')\n",
    "#print(pdf_folder_content)\n",
    "\n",
    "all_pdf_texts = []\n",
    "discussion_text = ''\n",
    "\n",
    "for pdf in pdf_folder_content:\n",
    "    \n",
    "    print(f'Analyzing {pdf}...')\n",
    "\n",
    "    try:\n",
    "       reader = PdfReader(f'{mypath}\\\\{pdf}')\n",
    "    except:\n",
    "        print(f'Error reading {pdf}!')\n",
    "        continue\n",
    "\n",
    "    n_pages = len(reader.pages)\n",
    "\t\n",
    "    print(f'{pdf} has {n_pages} pages!')\n",
    "\n",
    "    all_text = []\n",
    "\n",
    "    for i in range(0,n_pages):  \n",
    "        page_text = reader.pages[i].extract_text()\n",
    "        #print(page_text)\n",
    "        all_text.append(page_text)\n",
    "\n",
    "    \n",
    "\n",
    "    result_string = ' '.join(all_text)\n",
    "    all_pdf_texts.append(result_string)\n",
    "\n",
    "##SWITCH TO A DICTIONARY INSTEAD OF A LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "processed_text = [preprocess_text(text) for text in all_pdf_texts]\n",
    "\n",
    "corpus = corpora.Dictionary(processed_text)\n",
    "doc_term_matrix = [corpus.doc2bow(text) for text in processed_text]\n",
    "\n",
    "num_topics = 45\n",
    "\n",
    "lda_model = LdaModel(doc_term_matrix, id2word = corpus, num_topics = num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common topics and the number of instances are:\n",
      "Topic 9: Count 6\n",
      "Topic 4: Count 5\n",
      "Topic 28: Count 4\n",
      "Topic 5: Count 3\n",
      "Topic 19: Count 3\n",
      "Topic 10: Count 3\n",
      "Topic 38: Count 3\n",
      "Topic 17: Count 2\n",
      "Topic 40: Count 2\n",
      "Topic 7: Count 1\n",
      "Topic 21: Count 1\n",
      "Topic 23: Count 1\n",
      "Topic 12: Count 1\n",
      "Topic 20: Count 1\n",
      "Topic 22: Count 1\n",
      "Topic 8: Count 1\n",
      "Topic 36: Count 1\n",
      "Topic 39: Count 1\n",
      "Topic 24: Count 1\n",
      "Topic 30: Count 1\n",
      "Topic 15: Count 1\n",
      "Topic 37: Count 1\n",
      "Topic 42: Count 1\n",
      "Most used words in Topic 9: c, health, study, patient, heat, review, disease, n, climate, r\n",
      "Most used words in Topic 4: c, patient, study, heat, health, cardiac, may, arrest, disease, aneurysm\n",
      "Most used words in Topic 28: c, patient, study, heat, health, aneurysm, disease, cardiac, may, risk\n",
      "Most used words in Topic 5: patient, health, c, heat, study, air, aneurysm, disease, review, climate\n",
      "Most used words in Topic 19: health, c, air, heat, patient, study, disease, r, risk, aneurysm\n",
      "Most used words in Topic 10: patient, c, health, study, cardiac, air, review, risk, disease, artery\n",
      "Most used words in Topic 38: patient, c, cardiac, study, artery, disease, risk, aneurysm, arterial, may\n",
      "Most used words in Topic 17: heat, health, study, patient, review, c, disease, climate, air, temperature\n",
      "Most used words in Topic 40: c, patient, cardiac, risk, arrest, disease, study, green, artery, treatment\n",
      "Most used words in Topic 7: c, heat, health, patient, air, study, n, disease, cardiac, temperature\n",
      "Most used words in Topic 21: c, patient, heat, study, risk, aneurysm, arrest, cardiac, green, disease\n",
      "Most used words in Topic 23: patient, heat, study, health, c, air, aneurysm, disease, green, may\n",
      "Most used words in Topic 12: patient, c, heat, artery, aneurysm, disease, lower, health, study, risk\n",
      "Most used words in Topic 20: c, patient, study, aneurysm, artery, treatment, disease, surg, may, risk\n",
      "Most used words in Topic 22: patient, c, surg, heat, lower, artery, disease, aneurysm, may, renal\n",
      "Most used words in Topic 8: patient, c, disease, study, risk, aneurysm, artery, heat, surg, health\n",
      "Most used words in Topic 36: c, study, patient, disease, health, risk, heat, aneurysm, n, artery\n",
      "Most used words in Topic 39: c, patient, study, heat, disease, health, may, cardiac, artery, aneurysm\n",
      "Most used words in Topic 24: c, patient, study, health, air, artery, disease, aneurysm, risk, n\n",
      "Most used words in Topic 30: patient, c, study, disease, health, artery, green, air, urban, treatment\n",
      "Most used words in Topic 15: c, patient, cardiac, arrest, aneurysm, artery, study, risk, heat, health\n",
      "Most used words in Topic 37: c, patient, cardiac, arrest, study, resuscitation, disease, health, may, treatment\n",
      "Most used words in Topic 42: c, patient, cardiac, study, arrest, health, heat, disease, resuscitation, treatment\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "document_topics = [lda_model.get_document_topics(doc) for doc in doc_term_matrix]\n",
    "all_topics = [topic[0] for topics in document_topics for topic in topics]\n",
    "\n",
    "topics_nb = Counter(all_topics)\n",
    "\n",
    "most_nb_topics = [topic for topic, count in topics_nb.most_common()]\n",
    "print(\"The most common topics and the number of instances are:\")\n",
    "for topic, x in topics_nb.most_common():\n",
    "    print(f\"Topic {topic +1}: Count {x}\")\n",
    "for topic in most_nb_topics:\n",
    "    topics_words = lda_model.show_topic(topic)\n",
    "    most_words = [word for word, _ in topics_words]\n",
    "    print(f\"Most used words in Topic {topic +1}: {', '.join(most_words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the optimal number of topic for this model is: 15\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "# Function to compute coherence score\n",
    "def compute_coherence(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    # YOUR CODE HERE\n",
    "    coherence_values = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        lda_model = LdaModel(corpus = corpus, id2word = dictionary, num_topics = num_topics, random_state = 100)\n",
    "\n",
    "        coherence_model_lda = CoherenceModel(model = lda_model, texts = texts, dictionary = dictionary, coherence = 'c_v')\n",
    "        coherence_values.append(coherence_model_lda.get_coherence())\n",
    "    \n",
    "    return coherence_values\n",
    "\n",
    "coherence_values = compute_coherence(dictionary=corpus, corpus= doc_term_matrix, texts=processed_text, limit=50, start = 5, step=5)\n",
    "\n",
    "optimal_nb_topics = (coherence_values.index(max(coherence_values)) + 1) * 5\n",
    "print(f\"the optimal number of topic for this model is: {optimal_nb_topics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting coherence scores\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(5, 50, 5), coherence_values, marker='o')\n",
    "plt.xlabel(\"Number of Topics\")\n",
    "plt.ylabel(\"Coherence Score\")\n",
    "plt.title(\"LDA Coherence\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "#1 optimal number of topics\n",
    "optimal_number_topics = optimal_nb_topics\n",
    "\n",
    "#2 pre-process the full dataset\n",
    "processed_text = [preprocess_text(text) for text in all_pdf_texts]\n",
    "\n",
    "corpus = corpora.Dictionary(processed_text)\n",
    "doc_term_matrix = [corpus.doc2bow(text) for text in processed_text]\n",
    "\n",
    "#3 Fit the LDA Model:\n",
    "final_lda_model = LdaModel(corpus = doc_term_matrix, id2word = corpus, num_topics = optimal_number_topics)\n",
    "\n",
    "#4 Model Evaluation;\n",
    "final_coherence_model = CoherenceModel(model = final_lda_model, texts = processed_text, dictionary = corpus, coherence = 'c_v')\n",
    "final_coherence_score = final_coherence_model.get_coherence()\n",
    "print(f\"The final coherence score is of {final_coherence_score}\")\n",
    "#5 Refelctions: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
